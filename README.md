
# Insurance Model Refactor Documentation

This repository contains a refactored Python code for an insurance prediction model, utilizing various machine learning algorithms and data preprocessing techniques. The objective of the project is to predict whether a customer has a caravan insurance policy based on provided sociodemographic and product ownership data.

## Table of Contents
- [Overview](#overview)
- [Folder Structure](#folder-structure)
- [Installation](#installation)
- [Usage](#usage)
- [Code Details](#code-details)
  - [Data Preprocessing](#data-preprocessing)
  - [Model Training](#model-training)
  - [Evaluation](#evaluation)
- [File Descriptions](#file-descriptions)
- [Acknowledgments](#acknowledgments)

---

## Overview

This project aims to refine and improve the accuracy of a machine learning model for predicting caravan insurance ownership. It utilizes Python scripts and Jupyter notebooks to preprocess the data, train models, evaluate performance, and store artifacts such as trained models and results.

The key goals are:
1. Clean and preprocess data to prepare it for model training.
2. Train and compare different models to identify the best-performing algorithm.
3. Evaluate the model using standard metrics.
4. Refactor the code for better organization and readability.

## Folder Structure

The following directory structure organizes the files in this repository:

```
.
├── data/                      # Data files and Data Version Control (DVC) configurations
├── docs/                      # Documentation and description files
│   └── insurance-company-benchmark-coil-2000/  # Raw data and benchmark files
├── mlops_equipo29/            # Core Python package for MLOps
├── models/                    # Saved model files
│   ├── dt_model.pkl           # Decision Tree model
│   ├── insurance_model.pkl    # General insurance model
│   ├── lr_model.pkl           # Logistic Regression model
│   └── xgb_model.pkl          # XGBoost model
├── notebooks/                 # Jupyter notebooks for analysis and exploration
├── reports/                   # Reports and figures generated by the project
│   ├── figures/               # Figures and images for reports
├── references/                # References and research materials
├── README.md                  # Documentation file (this file)
├── requirements.txt           # Python dependencies
└── setup.cfg                  # Configuration for Python project
```

## Installation

To get started with this project, please install the required Python dependencies. It’s recommended to create a virtual environment first:

```bash
python3 -m venv env
source env/bin/activate
pip install -r requirements.txt
```

## Usage

1. Clone the repository.
2. Install the dependencies as outlined in the [Installation](#installation) section.
3. Prepare the data by placing it in the `data/` directory or following DVC commands if DVC is set up.
4. Run the Python script in `notebooks/Insurance_refactor_fully.py` for full model training and evaluation.

To execute specific functions, run the Jupyter notebook `Insurance.ipynb` to test individual parts of the pipeline.

### Running the Script

To run the main script for training and evaluation:

```bash
python notebooks/Insurance_refactor_fully.py
```

## Code Details

### Data Preprocessing

The code starts by loading the dataset and performing initial preprocessing steps. This includes:
- Handling missing values.
- Encoding categorical variables.
- Splitting data into training and testing sets.

### Model Training

The following models are trained:
- **Decision Tree** (`dt_model.pkl`): A simple tree-based model.
- **Logistic Regression** (`lr_model.pkl`): A linear model suited for binary classification.
- **XGBoost** (`xgb_model.pkl`): A powerful gradient-boosting algorithm.

Each model is saved in the `models/` directory after training for future use.

### Evaluation

The model performance is evaluated using common classification metrics:
- Accuracy
- Precision
- Recall
- F1 Score

These metrics are used to assess which model performs best in predicting insurance policy ownership.

## File Descriptions

- **data/**: Contains the dataset and DVC files to manage data versioning.
- **docs/**: Contains documentation files, including the original data description and benchmark details.
- **models/**: Stores serialized model files (`.pkl`) for Decision Tree, Logistic Regression, and XGBoost models.
- **notebooks/**: Jupyter notebooks for exploratory data analysis and detailed model testing.
  - `Insurance_refactor_fully.py`: Main Python script for refactored insurance model training and evaluation.
  - `Insurance.ipynb`: Jupyter notebook for interactive model testing and debugging.
- **reports/**: Contains generated reports and figures for performance analysis.
- **requirements.txt**: Lists the Python dependencies for the project.
- **setup.cfg**: Configuration file for the Python project setup.

## Acknowledgments

This project was developed with the support of [Team Name or Organization] and follows best practices in MLOps for model training and deployment.
