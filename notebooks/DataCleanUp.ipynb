{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09a8c3fd-d69f-423e-bb25-133e43af8e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29b0a06b-0d19-4f88-926a-679dc02a1514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with the updated file paths\n",
    "train_data = pd.read_csv('../data/raw/train/ticdata2000.txt', sep='\\t', header=None)\n",
    "eval_data = pd.read_csv('../data/raw/eval/ticeval2000.txt', sep='\\t', header=None)\n",
    "target_data = pd.read_csv('../data/raw/eval/tictgts2000.txt', sep='\\t', header=None, names=['Target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd11ff56-a3e9-4b9f-b704-bd2a1157a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = train_data.isnull().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364fc413-b7c8-4b8a-a16f-128da8604e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "# Load the content of the dictionary.txt file\n",
    "with open('../docs/insurance+company+benchmark+coil+2000/dictionary.txt', 'r', encoding='ISO-8859-1') as file:\n",
    "    file_content = file.read()\n",
    "\n",
    "\n",
    "# Extract the Data Dictionary table using regular expressions\n",
    "pattern = re.compile(r\"(\\d+)\\s+([A-Z]+[A-Z0-9]*)\\s+(.+?)(?=\\d+\\s+|L0:)\", re.DOTALL)\n",
    "matches = pattern.findall(file_content)\n",
    "\n",
    "# Create a DataFrame from the matches\n",
    "df = pd.DataFrame(matches, columns=['Nr', 'Name', 'Description'])\n",
    "\n",
    "# Clean up the 'Description' column to remove extra line breaks and spaces\n",
    "df['Description'] = df['Description'].str.replace('\\n', ' ').str.strip()\n",
    "\n",
    "# Convert 'Nr' column to integer\n",
    "df['Nr'] = df['Nr'].astype(int)\n",
    "\n",
    "# Display the DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03446f2b-5ae0-445a-9cfa-541bf35f92fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a pattern to extract each L table (L0, L1, L2, L3, L4)\n",
    "l_tables_pattern = re.compile(r\"(L\\d+):\\n\\n(.*?)\\n\\n\", re.DOTALL)\n",
    "l_tables_matches = l_tables_pattern.findall(file_content)\n",
    "\n",
    "# Dictionary to store the DataFrames\n",
    "l_tables_dict = {}\n",
    "\n",
    "# Process each L table\n",
    "for table_name, table_content in l_tables_matches:\n",
    "    # Split the table content into lines\n",
    "    lines = table_content.strip().split('\\n')\n",
    "    \n",
    "    # Split each line into two parts: value and label\n",
    "    data = [line.split(maxsplit=1) for line in lines if len(line.split(maxsplit=1)) == 2]\n",
    "    \n",
    "    # Create a DataFrame and store it in the dictionary\n",
    "    df1 = pd.DataFrame(data, columns=['Value', 'Label'])\n",
    "    l_tables_dict[table_name] = df1\n",
    "\n",
    "# Display the dictionary keys to confirm extraction\n",
    "l_tables_dict.keys()\n",
    "l_tables_dict['L0'] = l_tables_dict['L0'].iloc[1:].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f5fba7-7e31-4b41-bf6b-b615b3f2d57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of new column names using the 'Name' column from df\n",
    "new_column_names = df['Name'].tolist()\n",
    "\n",
    "# Rename the columns in train_data using the new_column_names list\n",
    "train_data.columns = new_column_names\n",
    "\n",
    "# Display the updated DataFrame\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8deeda5-f13e-4898-a10b-1542a0345a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a mapping dictionary for each L table\n",
    "l_mapping_dict = {}\n",
    "\n",
    "for l_name, df in l_tables_dict.items():\n",
    "    # Create a dictionary mapping 'Value' to 'Label'\n",
    "    mapping = dict(zip(df['Value'], df['Label']))\n",
    "    l_mapping_dict[l_name] = mapping\n",
    "\n",
    "# Step 2: Define a function to replace values using the appropriate mapping\n",
    "def replace_values(df, column, mapping_dict):\n",
    "    \"\"\"\n",
    "    Replace values in a DataFrame column using a mapping dictionary.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing the column to replace.\n",
    "        column (str): The column name to replace values for.\n",
    "        mapping_dict (dict): The dictionary to use for replacement.\n",
    "        \n",
    "    Returns:\n",
    "        pd.Series: The column with replaced values.\n",
    "    \"\"\"\n",
    "    return df[column].map(mapping_dict)\n",
    "\n",
    "column_to_mapping = {\n",
    "    'MOSTYPE': 'L0',\n",
    "    'MGEMLEEF': 'L1',\n",
    "    'MOSHOOFD': 'L2',\n",
    "    'MGODRK': 'L3',\n",
    "    'MGODPR': 'L3',\n",
    "    'MGODOV': 'L3',\n",
    "    'MGODGE': 'L3',\n",
    "    'PWAPART': 'L4',\n",
    "    'PWABEDR': 'L4',\n",
    "    'PWALAND': 'L4',\n",
    "}\n",
    "# Step 3: Convert only categorical columns to strings and update mapping dictionaries\n",
    "categorical_columns = list(column_to_mapping.keys())\n",
    "\n",
    "# Convert only the specified categorical columns to strings\n",
    "for column in categorical_columns:\n",
    "    if column in train_data.columns:\n",
    "        train_data[column] = train_data[column].astype(str)\n",
    "\n",
    "# Ensure mapping dictionary keys are strings\n",
    "for l_table, mapping in l_mapping_dict.items():\n",
    "    l_mapping_dict[l_table] = {str(k): v for k, v in mapping.items()}\n",
    "\n",
    "# Step 4: Replace values for the relevant columns in the dataset\n",
    "# Mapping the columns to their corresponding L tables from the Data Dictionary\n",
    "for column, l_table in column_to_mapping.items():\n",
    "    if column in train_data.columns:  # Ensure the column exists in the dataset\n",
    "        train_data[column] = replace_values(train_data, column, l_mapping_dict[l_table])\n",
    "\n",
    "# Step 5: Verify the replacement\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f07bd47-ec31-4bfe-b60d-336951f80b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6084d5-fb1e-46f8-ae95-fa6b1ba2b3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['CARAVAN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc4efaa-d71e-49f5-8026-1899d7fd8fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA - Distribution of the target variable\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(train_data['CARAVAN'])\n",
    "plt.title('Distribution of Caravan Insurance Policy (Target Variable)')\n",
    "plt.xlabel('Has Caravan Insurance')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d11229-9cff-4e78-94cd-0e1bdd3792bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "# Checking the correlation between features and the target\n",
    "correlation = train_data.corr()['CARAVAN'].sort_values(ascending=False)\n",
    "print(\"\\nTop 10 features positively correlated with CARAVAN:\")\n",
    "print(correlation.head(11)) # Including 'CARAVAN' itself\n",
    "\n",
    "print(\"\\nTop 10 features negatively correlated with CARAVAN:\")\n",
    "print(correlation.tail(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addc2f4e-f5e5-4b6c-b9c1-4cae4994ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for the first 43 columns and the CARAVAN column\n",
    "plt.figure(figsize=(18, 14))\n",
    "\n",
    "subset_corr = train_data.iloc[:, :43].join(train_data['CARAVAN']).corr()\n",
    "\n",
    "sns.heatmap(subset_corr, cmap='coolwarm', annot=False, fmt=\".2f\")\n",
    "plt.title('Correlation Matrix of the First 43 Attributes and CARAVAN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7287c35a-cce4-4799-9bec-c5c0ab75fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for the last 43 columns and the CARAVAN column\n",
    "plt.figure(figsize=(18, 14))\n",
    "\n",
    "subset_corr_last = train_data.iloc[:, -44:].corr()  # Includes the last 43 columns and CARAVAN\n",
    "\n",
    "sns.heatmap(subset_corr_last, cmap='coolwarm', annot=False, fmt=\".2f\")\n",
    "plt.title('Correlation Matrix of the Last 43 Attributes and CARAVAN')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd4b38-2f25-4e98-9950-fc3eda0ee727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display statistical summary for numerical features\n",
    "summary_stats = train_data.describe()\n",
    "print(\"Statistical Summary:\")\n",
    "print(summary_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908ddd39-0d4e-43fb-902e-11f2e38f0a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot histograms for all numerical features\n",
    "train_data.hist(bins=20, figsize=(20, 15))\n",
    "plt.suptitle('Histograms of Numerical Features')\n",
    "plt.show()\n",
    "\n",
    "# Compare distributions of features for customers with and without a caravan policy\n",
    "for col in train_data.columns:\n",
    "    if col != 'CARAVAN':  # Assuming 'CARAVAN' is the target column\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(data=train_data, x=col, hue='CARAVAN', multiple='stack', bins=20)\n",
    "        plt.title(f'Distribution of {col} for Caravan and Non-Caravan Customers')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0ab343-f7d1-4298-9e44-38d4c2c30a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use boxplots to identify outliers in numerical features\n",
    "for col in train_data.columns:\n",
    "    if train_data[col].dtype != 'object' and col != 'CARAVAN':\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.boxplot(x=train_data[col])\n",
    "        plt.title(f'Boxplot of {col}')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a843d47-7564-4bbf-8edb-356704de093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency analysis for categorical features\n",
    "categorical_columns = [col for col in train_data.columns if train_data[col].dtype == 'object']\n",
    "for col in categorical_columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x=train_data[col])\n",
    "    plt.title(f'Frequency of {col}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Cross-tabulation with the target variable\n",
    "for col in categorical_columns:\n",
    "    cross_tab = pd.crosstab(train_data[col], train_data['CARAVAN'])\n",
    "    print(f'Cross-tabulation for {col} with CARAVAN:')\n",
    "    display(cross_tab)  # Display the crosstab as a table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a91793-6d0c-42e4-9f75-ceb80df070a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a310dc32-0cd8-4a3b-b97f-f4396d0d3a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data shape:\", train_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4378f63f-cb5a-4bbf-8939-614fff9bc98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../docs/insurance+company+benchmark+coil+2000/ticdata2000.txt', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7ee9d08-38de-42cc-87b9-54234bf2118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'CARAVAN' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8644cc8-8a57-4df4-8ad0-95358dc96f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO WE REALLY NEED THIS ???\n",
    "# REPEAT WITH eval_data AND target_data ???\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# Step 1: Separate features and target\n",
    "X = train_data.drop(columns=[85])  # Drop the target column\n",
    "y = train_data[85]  # Column 85 represents the \"CARAVAN\" target\n",
    "\n",
    "\n",
    "# Step 2: Identify categorical and numerical features\n",
    "categorical_features = list(range(43))  # Columns 0-42 are considered categorical\n",
    "numerical_features = list(range(43, 85))  # Columns 43-84 are considered numerical\n",
    "\n",
    "# Step 3: Preprocessing pipelines for numerical and categorical data\n",
    "numerical_pipeline = Pipeline([\n",
    "    #('imputer', SimpleImputer(strategy='median')),  # Impute missing values with median / not needed bc there are no missing values \n",
    "    ('scaler', StandardScaler())  # Normalize numerical features\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    # ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute with most frequent value / not needed bc there are no missing values \n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features\n",
    "])\n",
    "\n",
    "# Step 4: Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, numerical_features),\n",
    "    ('cat', categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "# Step 5: Dimensionality reduction using TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=50)\n",
    "\n",
    "# Step 6: Complete pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('reduce_dim', svd)\n",
    "])\n",
    "\n",
    "# Apply the pipeline to the training data\n",
    "X_processed = pipeline.fit_transform(X)\n",
    "\n",
    "# Display the shape of the processed data\n",
    "print(\"Shape of the processed data:\", X_processed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8248643b-6e2f-491c-a57f-c9a4cb4bf45f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc290f6-22e4-4dbb-ad91-2a8883dab5b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
